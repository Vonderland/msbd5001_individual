{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = 12\n",
    "\n",
    "# use this path to run on kaggle\n",
    "# train_path = \"../input/msbd5001-fall2019/train.csv\"\n",
    "# test_path = \"../input/msbd5001-fall2019/test.csv\"\n",
    "\n",
    "# use this path to run on local\n",
    "train_path = \"../data/train.csv\"\n",
    "test_path = \"../data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "\n",
    "train = train.drop(columns=['id'])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_id = pd.read_csv(test_path)\n",
    "test = test_with_id.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['total_positive_reviews'] = train[['total_positive_reviews']].fillna(train[['total_positive_reviews']].mean())\n",
    "test['total_positive_reviews'] = test[['total_positive_reviews']].fillna(test[['total_positive_reviews']].mean())\n",
    "\n",
    "train['total_negative_reviews'] = train[['total_negative_reviews']].fillna(train[['total_negative_reviews']].mean())\n",
    "test['total_negative_reviews'] = test[['total_negative_reviews']].fillna(test[['total_negative_reviews']].mean())\n",
    "\n",
    "# fill with the mode\n",
    "train['purchase_date'] = train['purchase_date'].fillna(\"Jun 27, 2019\")\n",
    "test['purchase_date'] = test['purchase_date'].fillna(\"Oct 25, 2017\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering: calculate waiting days and own days\n",
    "train[\"waiting_days\"] = pd.to_datetime(train['purchase_date']) - pd.to_datetime(train['release_date'])\n",
    "test[\"waiting_days\"] = pd.to_datetime(test['purchase_date']) - pd.to_datetime(test['release_date'])\n",
    "train[\"own_days\"] =  pd.to_datetime('Dec 25, 2019')- pd.to_datetime(train['purchase_date'])\n",
    "test[\"own_days\"] = pd.to_datetime('Dec 25, 2019')- pd.to_datetime(test['purchase_date'])\n",
    "\n",
    "train[\"waiting_days\"] = pd.to_timedelta(train[\"waiting_days\"]).dt.days\n",
    "test[\"waiting_days\"] = pd.to_timedelta(test[\"waiting_days\"]).dt.days\n",
    "train[\"own_days\"] = pd.to_timedelta(train[\"own_days\"]).dt.days\n",
    "test[\"own_days\"] = pd.to_timedelta(test[\"own_days\"]).dt.days\n",
    "\n",
    "# because of the mode to fillna, some days maybe illegal, set them to 0\n",
    "train.waiting_days[train[\"waiting_days\"] < 0] = 0\n",
    "test.waiting_days[test[\"waiting_days\"] < 0] = 0\n",
    "train.waiting_days[train[\"own_days\"] < 0] = 0\n",
    "test.waiting_days[test[\"own_days\"] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bool\n",
    "train['is_free'] = train['is_free'].astype(int)\n",
    "test['is_free'] = test['is_free'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['purchase_date', 'release_date']\n",
    "\n",
    "train_rough = train.drop(columns=drop_columns)\n",
    "test_rough = test.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rough.drop(train_rough.price.nlargest(2).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_rough['playtime_forever']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_rough, y, random_state = 0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the words \n",
    "generes_list = train_X['genres'].str.split(',',expand=False).to_numpy()\n",
    "categories_list = train_X['categories'].str.split(',',expand=False).to_numpy()\n",
    "tags_list = train_X['tags'].str.split(',',expand=False).to_numpy()\n",
    "\n",
    "generes_set = {item for i in generes_list for item in i}\n",
    "categories_set = {item for i in categories_list for item in i}\n",
    "tags_set = {item for i in tags_list for item in i}\n",
    "\n",
    "generes_time_dict = {}\n",
    "categories_time_dict = {}\n",
    "tags_time_dict = {}\n",
    "\n",
    "# generate the mean of time corresponding to different tags\n",
    "for genere in generes_set:\n",
    "    count = np.sum(train_X['genres'].str.contains(genere))\n",
    "    generes_time_dict[genere] = np.sum(train_X[train_X['genres'].str.contains(genere)].playtime_forever) / count\n",
    "\n",
    "for category in categories_set:\n",
    "    count = np.sum(train_X['categories'].str.contains(category))\n",
    "    categories_time_dict[category] = np.sum(train_X[train_X['categories'].str.contains(category)].playtime_forever) / count\n",
    "\n",
    "for tag in tags_set:\n",
    "    count = np.sum(train_X['tags'].str.contains(tag))\n",
    "    tags_time_dict[tag] = np.sum(train_X[train_X['tags'].str.contains(tag)].playtime_forever) / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean(current_dict, current_str):\n",
    "    str_list = current_str.split(',')\n",
    "    num_list = [0]\n",
    "    for item in str_list:\n",
    "        if item in current_dict:\n",
    "            num_list.append(current_dict[item])\n",
    "    return np.mean(num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generes_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X['genres_time_mean'] = train_X['genres'].apply(lambda x: find_mean(generes_time_dict, x))\n",
    "train_X['categories_time_mean'] = train_X['categories'].apply(lambda x: find_mean(categories_time_dict, x))\n",
    "train_X['tags_time_mean'] = train_X['tags'].apply(lambda x: find_mean(tags_time_dict, x))\n",
    "\n",
    "val_X['genres_time_mean'] = val_X['genres'].apply(lambda x: find_mean(generes_time_dict, x))\n",
    "val_X['categories_time_mean'] = val_X['categories'].apply(lambda x: find_mean(categories_time_dict, x))\n",
    "val_X['tags_time_mean'] = val_X['tags'].apply(lambda x: find_mean(tags_time_dict, x))\n",
    "\n",
    "test_X = test_rough\n",
    "test_X['genres_time_mean'] = test_rough['genres'].apply(lambda x: find_mean(generes_time_dict, x))\n",
    "test_X['categories_time_mean'] = test_rough['categories'].apply(lambda x: find_mean(categories_time_dict, x))\n",
    "test_X['tags_time_mean'] = test_rough['tags'].apply(lambda x: find_mean(tags_time_dict, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X['categories_count'] = train_X['categories'].apply(lambda x: len(x.split(',')))\n",
    "val_X['categories_count'] = val_X['categories'].apply(lambda x: len(x.split(',')))\n",
    "test_X['categories_count'] = test_X['categories'].apply(lambda x: len(x.split(',')))\n",
    "\n",
    "train_X['tags_count'] = train_X['tags'].apply(lambda x: len(x.split(',')))\n",
    "val_X['tags_count'] = val_X['tags'].apply(lambda x: len(x.split(',')))\n",
    "test_X['tags_count'] = test_X['tags'].apply(lambda x: len(x.split(',')))\n",
    "\n",
    "train_X['genres_count'] = train_X['genres'].apply(lambda x: len(x.split(',')))\n",
    "val_X['genres_count'] = val_X['genres'].apply(lambda x: len(x.split(',')))\n",
    "test_X['genres_count'] = test_X['genres'].apply(lambda x: len(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.select_dtypes(exclude=['object'])\n",
    "val_X = val_X.select_dtypes(exclude=['object'])\n",
    "test_X = test_X.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.drop(columns=['playtime_forever'])\n",
    "val_X = val_X.drop(columns=['playtime_forever'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm it\n",
    "train_x_norm = (train_X - train_X.min()) / (train_X.max() - train_X.min())\n",
    "val_x_norm = (val_X - val_X.min()) / (val_X.max() - val_X.min())\n",
    "test_x_norm = (test_X - test_X.min()) / (test_X.max() - test_X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors=20, \n",
    "                                leaf_size=15, \n",
    "                                p=4)\n",
    "knn_model.fit(train_x_norm, train_y)\n",
    "knn_rough_preds = knn_model.predict(train_x_norm)\n",
    "print(sqrt(mean_squared_error(train_y, knn_rough_preds)))\n",
    "knn_rough_preds = knn_model.predict(val_x_norm)\n",
    "print(sqrt(mean_squared_error(val_y, knn_rough_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rough_predict = knn_model.predict(test_x_norm)\n",
    "output = pd.DataFrame(pd.DataFrame({\n",
    "        \"id\": test_with_id.id,\n",
    "        \"playtime_forever\": test_rough_predict\n",
    "    }))\n",
    "\n",
    "\n",
    "output.to_csv(\"knn_submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
